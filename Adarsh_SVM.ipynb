{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3OKaJD92nOH",
        "outputId": "b262b70e-b286-4a8e-e403-42f52acc9f6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n",
            "Loading dataset from Google Drive...\n",
            "Dataset loaded successfully with 162980 rows and 2 columns.\n",
            "Checking for missing or infinite values in 'category' column:\n",
            "8698\n",
            "0\n",
            "Dropping rows with missing 'category' values...\n",
            "After cleaning, dataset has 154282 rows.\n",
            "Converting 'category' column to integer...\n",
            "Checking for missing or empty 'Text' data:\n",
            "4\n",
            "0\n",
            "Removing rows with missing or empty 'Text' data...\n",
            "After cleaning, dataset has 154277 rows.\n",
            "Selected 20% of the data, now 30855 rows.\n",
            "Splitting data into training and test sets...\n",
            "Training set size: 24684, Test set size: 6171\n",
            "Transforming text data into TF-IDF vectors...\n",
            "Text data transformed successfully.\n",
            "Training SVM model...\n",
            "SVM model training completed.\n",
            "Making predictions on the test set...\n",
            "Evaluation results:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.88      0.73      0.80      1357\n",
            "           0       0.87      0.98      0.92      2067\n",
            "           1       0.91      0.90      0.91      2747\n",
            "\n",
            "    accuracy                           0.89      6171\n",
            "   macro avg       0.89      0.87      0.88      6171\n",
            "weighted avg       0.89      0.89      0.89      6171\n",
            "\n",
            "Accuracy: 0.8898071625344353\n",
            "Saving predictions to Google Drive...\n",
            "Test results saved to: /content/drive/My Drive/test_results.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -q scikit-learn pandas\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully.\")\n",
        "\n",
        "\n",
        "print(\"Loading dataset from Google Drive...\")\n",
        "file_path = '/content/drive/My Drive/train3.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "print(f\"Dataset loaded successfully with {data.shape[0]} rows and {data.shape[1]} columns.\")\n",
        "\n",
        "\n",
        "print(\"Checking for missing or infinite values in 'category' column:\")\n",
        "print(data['category'].isnull().sum())\n",
        "print((data['category'] == float('inf')).sum())\n",
        "\n",
        "\n",
        "print(\"Dropping rows with missing 'category' values...\")\n",
        "data = data.dropna(subset=['category'])\n",
        "print(f\"After cleaning, dataset has {data.shape[0]} rows.\")\n",
        "\n",
        "\n",
        "print(\"Converting 'category' column to integer...\")\n",
        "data['category'] = data['category'].astype(int)\n",
        "\n",
        "\n",
        "print(\"Checking for missing or empty 'Text' data:\")\n",
        "print(data['Text'].isnull().sum())\n",
        "print((data['Text'] == '').sum())\n",
        "\n",
        "print(\"Removing rows with missing or empty 'Text' data...\")\n",
        "data = data.dropna(subset=['Text'])\n",
        "data = data[data['Text'].str.strip() != '']\n",
        "print(f\"After cleaning, dataset has {data.shape[0]} rows.\")\n",
        "\n",
        "\n",
        "data_sample = data.sample(frac=0.8, random_state=42)\n",
        "print(f\"Selected 20% of the data, now {data_sample.shape[0]} rows.\")\n",
        "\n",
        "\n",
        "print(\"Splitting data into training and test sets...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data_sample['Text'], data_sample['category'], test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n",
        "\n",
        "\n",
        "print(\"Transforming text data into TF-IDF vectors...\")\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "print(\"Text data transformed successfully.\")\n",
        "\n",
        "\n",
        "print(\"Training SVM model...\")\n",
        "svm_model = SVC(kernel=\"linear\", probability=True)\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "print(\"SVM model training completed.\")\n",
        "\n",
        "\n",
        "print(\"Making predictions on the test set...\")\n",
        "y_pred = svm_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Evaluation results:\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "print(\"Saving predictions to Google Drive...\")\n",
        "test_results = pd.DataFrame({\n",
        "    \"Text\": X_test,\n",
        "    \"Predicted Sentiment\": y_pred\n",
        "})\n",
        "\n",
        "\n",
        "output_path = '/content/drive/My Drive/test_results.csv'\n",
        "test_results.to_csv(output_path, index=False)\n",
        "print(f\"Test results saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tn5ETpqHS-nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading test dataset (test3.csv) from Google Drive...\")\n",
        "test_file_path = '/content/drive/My Drive/test3.csv'\n",
        "test_data = pd.read_csv(test_file_path)\n",
        "print(f\"Test dataset loaded successfully with {test_data.shape[0]} rows and {test_data.shape[1]} columns.\")\n",
        "\n",
        "print(\"Checking for missing or empty 'Text' data in test3.csv:\")\n",
        "\n",
        "\n",
        "print(\"Removing rows with missing or empty 'Text' data in test3.csv...\")\n",
        "test_data = test_data.dropna(subset=['Text'])\n",
        "test_data = test_data[test_data['Text'].str.strip() != '']\n",
        "print(f\"After cleaning, test dataset has {test_data.shape[0]} rows.\")\n",
        "\n",
        "\n",
        "print(\"Transforming test data into TF-IDF vectors...\")\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_test_tfidf = tfidf.fit_transform(test_data['Text'])\n",
        "print(\"Test data transformed successfully.\")\n",
        "\n",
        "\n",
        "print(\"Making predictions on the test dataset (test3.csv)...\")\n",
        "y_pred = svm_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Saving predictions to Google Drive...\")\n",
        "test_results = pd.DataFrame({\n",
        "    \"Text\": test_data['Text'],\n",
        "    \"Predicted Sentiment\": y_pred\n",
        "})\n",
        "\n",
        "output_path = '/content/drive/My Drive/test3_predictions_svm.csv'\n",
        "test_results.to_csv(output_path, index=False)\n",
        "print(f\"Test results saved to: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3y3JG9PZIoD",
        "outputId": "0cb09985-85d4-4d1e-e976-6af72573cccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test dataset (test3.csv) from Google Drive...\n",
            "Test dataset loaded successfully with 12981 rows and 2 columns.\n",
            "Checking for missing or empty 'Text' data in test3.csv:\n",
            "3\n",
            "0\n",
            "Removing rows with missing or empty 'Text' data in test3.csv...\n",
            "After cleaning, test dataset has 12978 rows.\n",
            "Transforming test data into TF-IDF vectors...\n",
            "Test data transformed successfully.\n",
            "Making predictions on the test dataset (test3.csv)...\n",
            "Saving predictions to Google Drive...\n",
            "Test results saved to: /content/drive/My Drive/test3_predictions_svm.csv\n"
          ]
        }
      ]
    }
  ]
}